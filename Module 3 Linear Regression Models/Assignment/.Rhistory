data(ChemicalManufacturingProcess)
?ChemicalManufacturingProcess
# Determine each predictor's missing values
ChemicalManufacturingProcess[ChemicalManufacturingProcess == ""] <- NA
na_value <- sapply(ChemicalManufacturingProcess, function(x) sum(is.na(x)))
predictors_with_missing <- names(na_value[na_value > 0])
missing_values_table <- data.frame(Predictor = predictors_with_missing,
Missing_Values = na_value[predictors_with_missing])
missing_values_table |> gt() |>
tab_header(title = "Predictors with Missing Values") |>  slice(1:5)
# Determine each predictor's missing values
ChemicalManufacturingProcess[ChemicalManufacturingProcess == ""] <- NA
na_value <- sapply(ChemicalManufacturingProcess, function(x) sum(is.na(x)))
predictors_with_missing <- names(na_value[na_value > 0])
missing_values_table <- data.frame(Predictor = predictors_with_missing,
Missing_Values = na_value[predictors_with_missing])
missing_values_table |> gt() |>
tab_header(title = "Predictors with Missing Values") |>  head(5)
# Imputation by MICE (Multiple Imputation by Chained Equations)
imputed_data <- mice(ChemicalManufacturingProcess)
CMfgP_df <- complete(imputed_data)
# Visualize missing values after imputation
vis_miss(CMfgP_df)
# Determine each predictor's missing values
ChemicalManufacturingProcess[ChemicalManufacturingProcess == ""] <- NA
na_value <- sapply(ChemicalManufacturingProcess, function(x) sum(is.na(x)))
predictors_with_missing <- names(na_value[na_value > 0])
missing_values_table <- data.frame(Predictor = predictors_with_missing,
Missing_Values = na_value[predictors_with_missing])
missing_values_table |> gt() |>
tab_header(title = "Predictors with Missing Values") |>  head(5)
# Imputation by MICE (Multiple Imputation by Chained Equations)
imputed_data <- mice(ChemicalManufacturingProcess)
library(caret)
library(AppliedPredictiveModeling)
library(dplyr)
library(ggplot2)
library(factoextra)
library(corrplot)
library(car)
library(knitr)
library(gt)
library(naniar)
library(mice)
# ... add additional libraries here ...
# Upload data tecator data frames
data(tecator)
?tecator
# Combine IR predictors and fat content outcome into a new data frame
fat_outcome <- endpoints[,2]
IR_fat <- cbind(absorp, Fat = fat_outcome)
IR_fat <- as.data.frame(IR_fat)
# Perform PCA on the absorp data frame
pca_result <- prcomp(IR_fat, scale = TRUE)
#summary(pca_result)
# Visualize variance explained by each principal component
fviz_eig(pca_result, addlabels = TRUE, ylim = c(0, 110), geom = "line")
# Determine effective dimension
var_explained <- pca_result$sdev^2 / sum(pca_result$sdev^2)
cumsum_var_explained <- cumsum(var_explained)
effective_dim <- which.max(cumsum_var_explained >= 0.9)
cat("The effective dimension (number of principal components needed to
explain 90% of variance) is:", effective_dim)
# Remove highly correlated predictors
correlation_matrix <- cor(IR_fat[, -1])
highly_correlated <- findCorrelation(correlation_matrix, cutoff = 0.9998)
highly_correlated_names <- colnames(IR_fat[, -1])[highly_correlated]
IR_fat_reduced <- IR_fat[, -highly_correlated]
#| warnings: false
# Create a list of N folds K-Fold CV
set.seed(123)
ctrl <- trainControl(method = "cv", number = 3)
folds <- createFolds(IR_fat_reduced$Fat, k = 3)
models <- list()
for(i in 1:3) {
train_data <- IR_fat_reduced[-folds[[i]], ]
test_data <- IR_fat_reduced[folds[[i]], ]
# Build Linear Regression Model
lm_model <- train(Fat ~ .,
data = train_data,
method = "lm",
trControl = ctrl,
preProcess = c("center", "scale"))
models[[paste("lm_Model", i, sep = "_")]] <- lm_model
# Create Partial Least Squeare Model
pls_model <- train(Fat ~ .,
data = train_data,
method = "pls",
trControl = ctrl,
preProcess = c("center", "scale"))
models[[paste("pls_Model", i, sep = "_")]] <- pls_model
# Create Ridge Regression Model
ridgeGrid <- expand.grid(lambda = seq(0, 0.1, length = 5))
ridge_model <- train(Fat ~ .,
data = train_data,
method = "ridge",
tuneGrid = ridgeGrid,
trControl = ctrl,
preProcess = c("center", "scale"))
models[[paste("ridge_Model", i, sep = "_")]] <- ridge_model
# Create Lasso Regression Model
lasGrid <- expand.grid(fraction = seq(0.001, 1, length = 5))
lasso_model <- train(Fat ~ .,
data = train_data,
method = "lasso",
tuneGrid = lasGrid,
trControl = ctrl,
preProcess = c("center", "scale"))
models[[paste("lasso_model", i, sep = "_")]] <- lasso_model
#Create Elastic Net Models
enetGrid <- expand.grid(alpha = seq(0, 1, by = 0.4),
lambda = seq(0, 1, by = 0.4))
elastic_net_model <- train(Fat ~ .,            # Outcome variable and all predictors
data = train_data,      # Dataset
method = "glmnet",     # Elastic Net method
trControl = ctrl,      # Cross-validation control
tuneGrid = enetGrid, # Grid of tuning parameters (alpha)
preProcess = c("center", "scale"))  # Standardize predictors
models[[paste("elastic_net_model", i, sep = "_")]] <- elastic_net_model}
models
# Train model evaluation
train_metrics <- resamples(list(OLS = lm_model, PLS = pls_model,
Lasso = lasso_model,
Enet = elastic_net_model))
summary(train_metrics)
dotplot(train_metrics)
library(AppliedPredictiveModeling)
data(permeability)
?permeability
permdf <- as.data.frame(cbind(fingerprints,
Perm = permeability))
# Remove low frequency predictors
filtered_permdf <- permdf[, -nearZeroVar(permdf)]
remaining_predictors <- ncol(filtered_permdf) - 1
cat("Predictors left after low frequencies are removed:",
remaining_predictors)
# Split data into 80% training and 20% test set
set.seed(123)
train_index0 <- createDataPartition(filtered_permdf$permeability,
p = 0.8, list = FALSE)
train_data0 <- filtered_permdf[train_index0, ]
test_data0 <- filtered_permdf[-train_index0, ]
# Create PLS model with tuning
ctrl0 <- trainControl(method = "cv", number = 5)
pls_tune <- train(permeability ~ .,
data = train_data0,
method = "pls",
trControl = ctrl0,
tuneGrid = data.frame(ncomp = 1:10),
preProcess = c("center", "scale"))
# Determine the number of optimal latent variables
optimal_lv_pls <- pls_tune$bestTune$ncomp
if(is.null(optimal_lv_pls)) {
print("Error: Unable to determine the optimal number of latent variables.")
} else {
print(paste("Optimal number of latent variables:", optimal_lv_pls))
# Fit the final PLS model using the optimal number of latent variables
pls_model <- caret::train(permeability ~ .,
data = train_data0,
method = "pls",
trControl = ctrl0,
preProcess = c("center", "scale"),
tuneGrid = expand.grid(ncomp = optimal_lv_pls))
# Evaluate the model performance
R2_pls <- pls_model$results$Rsquared
print(paste("Resampled estimate of R2:", round(R2_pls,4)))}
# Predict the response for the test set
test_pred_pls <- predict(pls_model, newdata = test_data0)
# Evaluate the model performance
test_R2_pls <- (cor(test_pred_pls, test_data0$permeability))^2
print(paste("Test set estimate of R2:", round(test_R2_pls,4)*100))
# Create Ridge Regression Model: Optimized
ridge_grid <- expand.grid(lambda = seq(0.01, 1, length = 10))
ridge_tune <- train(permeability ~ .,
data = train_data0,
method = "ridge",
tuneGrid = ridge_grid,
trControl = ctrl0,
preProcess = c("center", "scale"))
optimal_lv_lambda <- ridge_tune$bestTune$lambda
ridge_model <- train(permeability ~ .,
data = train_data0,
method = "ridge",
trControl = ctrl0,
preProcess = c("center", "scale"),
tuneGrid = data.frame(lambda = optimal_lv_lambda))
# Create Lasso Regression Model: Optimized
lasGrid0 <- expand.grid(fraction = seq(0.001, 1, length = 5))
lasso_tune <- train(permeability ~ .,
data = train_data0,
method = "lasso",
tuneGrid = lasGrid0,
trControl = ctrl0,
preProcess = c("center", "scale"))
optimal_lv_las <- lasso_tune$bestTune$fraction
lasso_model <- train(permeability ~ .,
data = train_data0,
method = "lasso",
trControl = ctrl0,
preProcess = c("center", "scale"),
tuneGrid = expand.grid(fraction = optimal_lv_las))
#Create Elastic Net Models: Optimized
enetGrid0 <- expand.grid(alpha = seq(0, 1, by = 0.1),
lambda = seq(0.1, 1, by = 0.1))
elastic_net_tune <- train(permeability ~ .,
data = train_data0,
method = "glmnet",
trControl = ctrl0,
tuneGrid = enetGrid0,
preProcess = c("center", "scale"))
optimal_lv_eneta <- elastic_net_tune$bestTune$alpha
optimal_lv_enetl <- elastic_net_tune$bestTune$lambda
elastic_net_model <- train(permeability ~ .,
data = train_data0,
method = "glmnet",
trControl = ctrl0,
preProcess = c("center", "scale"),
tuneGrid = expand.grid(alpha = optimal_lv_eneta,
lambda = optimal_lv_enetl))
# Run predictions on test data set and determine R^2s
ridge_test_R2 <- cor(predict(ridge_model, newdata = test_data0),
test_data0$permeability)^2
lasso_test_R2 <- cor(predict(lasso_model, newdata = test_data0),
test_data0$permeability)^2
elastic_net_test_R2 <- cor(predict(elastic_net_model, newdata = test_data0),
test_data0$permeability)^2
# Train R^2 scores
R2_ridge <- ridge_model$results$Rsquared
R2_lasso <- lasso_model$results$Rsquared
R2_enet <- elastic_net_model$results$Rsquared
# Table R-squared results for train and test data set
model_results <- data.frame(
Model = c("PLS","Ridge", "Lasso", "ENet"),
R2_oTrain = c(round(R2_pls,4)*100,round(R2_ridge,4)*100,
round(R2_lasso,4)*100,round(R2_enet,4)*100),
R2_Test = c(round(test_R2_pls,4)*100,round(ridge_test_R2,4)*100,
round(lasso_test_R2,4)*100, round(elastic_net_test_R2,4)*100))
knitr::kable(model_results, caption = "Test R2 Scores for Different Models")
library(AppliedPredictiveModeling)
data(ChemicalManufacturingProcess)
?ChemicalManufacturingProcess
# Determine each predictor's missing values
ChemicalManufacturingProcess[ChemicalManufacturingProcess == ""] <- NA
na_value <- sapply(ChemicalManufacturingProcess, function(x) sum(is.na(x)))
predictors_with_missing <- names(na_value[na_value > 0])
missing_values_table <- data.frame(Predictor = predictors_with_missing,
Missing_Values = na_value[predictors_with_missing])
missing_values_table |> gt() |>
tab_header(title = "Predictors with Missing Values") |>  head(5)
# Imputation by MICE (Multiple Imputation by Chained Equations)
imputed_data <- mice(ChemicalManufacturingProcess)
CMfgP_df <- complete(imputed_data)
# Visualize missing values after imputation
vis_miss(CMfgP_df)
# Split data into 80% training and 20% test set
set.seed(123)
train_index1 <- createDataPartition(CMfgP_df$Yield, p = 0.8, list = FALSE)
train_data1 <- CMfgP_df[train_index1, ]
test_data1 <- CMfgP_df[-train_index1, ]
# Perform center and scaling on the train and test data
train_predictors <- subset(train_data1, select = -Yield)
train_outcome <- train_data1$Yield
test_predictors <- subset(test_data1, select = -Yield)
test_outcome <- test_data1$Yield
preproc_train <- preProcess(train_predictors, method = c("center", "scale"))
scaled_train_predictors <- predict(preproc_train, train_predictors)
scaled_test_predictors <- predict(preproc_train, test_predictors)
scaled_train_data <- cbind(Yield = train_outcome, scaled_train_predictors)
scaled_test_data <- cbind(Yield = test_outcome, scaled_test_predictors)
set.seed(123)
ctrl1 <- trainControl(method = "cv", number = 5)
# Create PLS Regression Model: Optimized
pls_tune1 <- train(Yield ~ .,
data = scaled_train_data,
method = "pls",
trControl = ctrl1,
tuneGrid = data.frame(ncomp = 1:10))
optimal_pls <- pls_tune1$bestTune$ncomp
pls_model1 <- caret::train(Yield ~ .,
data = scaled_train_data,
method = "pls",
trControl = ctrl1,
tuneGrid = expand.grid(ncomp = optimal_pls))
# Create Ridge Regression Model: Optimized
ridge_grid1 <- expand.grid(lambda = seq(0.01, 10, length = 10))
ridge_tune1 <- train(Yield ~ .,
data = scaled_train_data,
method = "ridge",
tuneGrid = ridge_grid1,
trControl = ctrl1)
optimal_lambda <- ridge_tune1$bestTune$lambda
ridge_model1 <- train(Yield ~ .,
data = scaled_train_data,
method = "ridge",
trControl = ctrl1,
tuneGrid = data.frame(lambda = optimal_lambda))
# Create Lasso Regression Model: Optimized
lasGrid1 <- expand.grid(fraction = seq(0.001, 1, length = 5))
lasso_tune1 <- train(Yield ~ .,
data = scaled_train_data,
method = "lasso",
tuneGrid = lasGrid1,
trControl = ctrl1)
optimal_las <- lasso_tune1$bestTune$fraction
lasso_model1 <- train(Yield ~ .,
data = scaled_train_data,
method = "lasso",
trControl = ctrl1,
tuneGrid = expand.grid(fraction = optimal_las))
#Create Elastic Net Models: Optimized
enetGrid1 <- expand.grid(alpha = seq(0, 1, by = 0.1),
lambda = seq(0.1, 1, by = 0.1))
elastic_net_tune1 <- train(Yield ~ .,
data = scaled_train_data,
method = "glmnet",
trControl = ctrl1,
tuneGrid = enetGrid1)
optimal_eneta <- elastic_net_tune1$bestTune$alpha
optimal_enetl <- elastic_net_tune1$bestTune$lambda
elastic_net_model1 <- train(Yield ~ .,
data = scaled_train_data,
method = "glmnet",
trControl = ctrl1,
tuneGrid = expand.grid(alpha = optimal_eneta,
lambda = optimal_enetl))
# Regression optimal model's RMSE score
pls_optimal_rmse <- pls_model1$results$RMSE
ridge_optimal_rmse <- ridge_model1$results$RMSE
lasso_optimal_rmse <- lasso_model1$results$RMSE
elastic_net_optimal_rmse <- elastic_net_model1$results$RMSE
# Table RMSE results
model_names <- c("PLS", "Ridge", "Lasso", "Elastic Net")
optimal_RMSE <- c(pls_optimal_rmse, ridge_optimal_rmse,
lasso_optimal_rmse, elastic_net_optimal_rmse)
optimal_RMSE_df <- data.frame(Model = model_names,
Optimal_Train_RMSE = optimal_RMSE)
optimal_RMSE_df |> gt() |> tab_header(
title = "RMSE for Each Optimized Model")
# Perform predictions on test data sets
predictions <- list(
PLS = predict(pls_model1, newdata = scaled_test_data),
Ridge = predict(ridge_model1, newdata = scaled_test_data),
Lasso = predict(lasso_model1, newdata = scaled_test_data),
Elastic_Net = predict(elastic_net_model1, newdata = scaled_test_data))
# Calculate RMSE on test data set
calc_rmse <- function(actual, predicted) {
sqrt(mean((actual - predicted)^2))}
rmse_scores <- sapply(predictions, function(pred)
calc_rmse(scaled_test_data$Yield, pred))
# Table RMSE results
optimal_RMSE_df <- data.frame(Model = model_names,
Optimal_Train_RMSE = optimal_RMSE,
Test_RMSE = rmse_scores)
optimal_RMSE_df |> gt() |> tab_header(
title = "RMSE Score for Each Model")
# Extract coefficients from the final model: Elastic Net Model
coef_values <- predict(elastic_net_model1$finalModel, type = "coefficients")
predictor_names <- colnames(scaled_train_data)[!colnames(scaled_train_data) %in% "Yield"]
coef_df <- data.frame(Predictor = c("Intercept", predictor_names),
Coefficient = c(coef_values[1], coef_values[-1]))
nonzero_coefs <- coef_df[coef_df$Coefficient != 0, ]
nonzero_coefs <- nonzero_coefs[nonzero_coefs$Predictor != "Intercept", ]
nonzero_coefs_unique <- nonzero_coefs |>
group_by(Predictor) |>
slice(which.max(abs(Coefficient))) |>
ungroup()
# Count predictors unique manufacturing and biological predictors
manufacturing_process_count <- sum(grepl("ManufacturingProcess",
nonzero_coefs_unique$Predictor))
biological_material_count <- sum(grepl("BiologicalMaterial",
nonzero_coefs_unique$Predictor))
cat("Total count of unique predictors with 'ManufacturingProcess':",
manufacturing_process_count, "\n")
cat("Total count of unique predictors with 'BiologicalMaterial':",
biological_material_count, "\n")
# Print top five unique predictors with highest coefficient
nonzero_coefs_unique |> arrange(desc(abs(Coefficient))) |>
slice(1:5)|> gt() |> tab_header(
title = "Unique Predictors with Highest Coefficient")
library(caret)
library(AppliedPredictiveModeling)
library(dplyr)
library(ggplot2)
library(factoextra)
library(corrplot)
library(car)
library(knitr)
library(gt)
library(naniar)
library(mice)
# ... add additional libraries here ...
# Remove low frequency predictors
filtered_permdf <- permdf[, -nearZeroVar(permdf)]
library(AppliedPredictiveModeling)
data(permeability)
?permeability
permdf <- as.data.frame(cbind(fingerprints,
Perm = permeability))
# Remove low frequency predictors
filtered_permdf <- permdf[, -nearZeroVar(permdf)]
remaining_predictors <- ncol(filtered_permdf) - 1
cat("Predictors left after low frequencies are removed:",
remaining_predictors)
# Split data into 80% training and 20% test set
set.seed(123)
train_index0 <- createDataPartition(filtered_permdf$permeability,
p = 0.8, list = FALSE)
train_data0 <- filtered_permdf[train_index0, ]
test_data0 <- filtered_permdf[-train_index0, ]
# Create PLS model with tuning
ctrl0 <- trainControl(method = "cv", number = 5)
pls_tune <- train(permeability ~ .,
data = train_data0,
method = "pls",
trControl = ctrl0,
tuneGrid = data.frame(ncomp = 1:10),
preProcess = c("center", "scale"))
# Determine the number of optimal latent variables
optimal_lv_pls <- pls_tune$bestTune$ncomp
if(is.null(optimal_lv_pls)) {
print("Error: Unable to determine the optimal number of latent variables.")
} else {
print(paste("Optimal number of latent variables:", optimal_lv_pls))
# Fit the final PLS model using the optimal number of latent variables
pls_model <- caret::train(permeability ~ .,
data = train_data0,
method = "pls",
trControl = ctrl0,
preProcess = c("center", "scale"),
tuneGrid = expand.grid(ncomp = optimal_lv_pls))
# Evaluate the model performance
R2_pls <- pls_model$results$Rsquared
print(paste("Resampled estimate of R2:", round(R2_pls,4)))}
# Predict the response for the test set
test_pred_pls <- predict(pls_model, newdata = test_data0)
# Evaluate the model performance
test_R2_pls <- (cor(test_pred_pls, test_data0$permeability))^2
print(paste("Test set estimate of R2:", round(test_R2_pls,4)*100))
# Create Ridge Regression Model: Optimized
ridge_grid <- expand.grid(lambda = seq(0.01, 1, length = 10))
ridge_tune <- train(permeability ~ .,
data = train_data0,
method = "ridge",
tuneGrid = ridge_grid,
trControl = ctrl0,
preProcess = c("center", "scale"))
library(caret)
library(AppliedPredictiveModeling)
library(dplyr)
library(ggplot2)
library(factoextra)
library(corrplot)
library(car)
library(knitr)
library(gt)
library(naniar)
library(mice)
# ... add additional libraries here ...
library(AppliedPredictiveModeling)
data(ChemicalManufacturingProcess)
?ChemicalManufacturingProcess
# Determine each predictor's missing values
ChemicalManufacturingProcess[ChemicalManufacturingProcess == ""] <- NA
na_value <- sapply(ChemicalManufacturingProcess, function(x) sum(is.na(x)))
predictors_with_missing <- names(na_value[na_value > 0])
missing_values_table <- data.frame(Predictor = predictors_with_missing,
Missing_Values = na_value[predictors_with_missing])
missing_values_table |> gt() |>
tab_header(title = "Predictors with Missing Values") |> head(5)
# Imputation by MICE (Multiple Imputation by Chained Equations)
imputed_data <- mice(ChemicalManufacturingProcess)
CMfgP_df <- complete(imputed_data)
# Visualize missing values after imputation
vis_miss(CMfgP_df)
# Determine each predictor's missing values
ChemicalManufacturingProcess[ChemicalManufacturingProcess == ""] <- NA
na_value <- sapply(ChemicalManufacturingProcess, function(x) sum(is.na(x)))
predictors_with_missing <- names(na_value[na_value > 0])
missing_values_table <- data.frame(Predictor = predictors_with_missing,
Missing_Values = na_value[predictors_with_missing])
missing_values_table |> gt() |>
tab_header(title = "Predictors with Missing Values")
# Imputation by MICE (Multiple Imputation by Chained Equations)
imputed_data <- mice(ChemicalManufacturingProcess)
CMfgP_df <- complete(imputed_data)
# Visualize missing values after imputation
vis_miss(CMfgP_df)
# Determine each predictor's missing values
ChemicalManufacturingProcess[ChemicalManufacturingProcess == ""] <- NA
na_value <- sapply(ChemicalManufacturingProcess, function(x) sum(is.na(x)))
predictors_with_missing <- names(na_value[na_value > 0])
missing_values_table <- data.frame(Predictor = predictors_with_missing,
Missing_Values = na_value[predictors_with_missing])
missing_values_table |> head() |> gt() |>
tab_header(title = "Predictors with Missing Values")
# Imputation by MICE (Multiple Imputation by Chained Equations)
imputed_data <- mice(ChemicalManufacturingProcess)
CMfgP_df <- complete(imputed_data)
# Visualize missing values after imputation
vis_miss(CMfgP_df)
library(caret)
library(AppliedPredictiveModeling)
library(dplyr)
library(ggplot2)
library(factoextra)
library(corrplot)
library(car)
library(knitr)
library(gt)
library(naniar)
library(mice)
# ... add additional libraries here ...
