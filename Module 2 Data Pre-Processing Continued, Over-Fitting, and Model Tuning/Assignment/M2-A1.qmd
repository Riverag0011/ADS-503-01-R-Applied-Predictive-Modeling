---
title: "Week2, Assignment 1"
author: "Student Name"
format: 
    html: 
        toc: true
    pdf: default
editor: visual
---

```{r warning=FALSE, message=FALSE}
library(caret)
# ... add additional libraries here ...
library(tidyverse)
library(scales)
```

## Problem 2.1 (20 points)

The soybean data can also be found at the UC Irvine Machine Learning Repository. Data were collected to predict disease in 683 soybeans. The 35 predictors are mostly categorical and include information on the environmental conditions (e.g., temperature, precipitation) and plant conditions (e.g., left spots, mold growth). The outcome labels consist of 19 distinct classes. The data can be loaded via:

```{r}
library(mlbench)
data(Soybean)
# Use ?Soybean for details
```

### 2.1.a (10 points)

**Investigate missing values for all the predictors, which predictors have the highest and the lowest number of missing values?**

```{r}
# ... code ...
```

*... optional observation ...*

**Do the missing values depend on the outcome labels (summarize NAs by class)?**

**Hint**: `complete.cases(df)` will return a vector of TRUE/FALSE (if all values are present). You are trying to determine whether you can infer something about the `Class` for an an observation, given that one of the predictor values is missing.

```{r}
# ... code ...
```

* ... answer ... *

**Are any of the distributions degenerate in the ways discussed earlier in chapter 3?**

```{r}
# ... code ...
```

* ... answer ... *

### 2.1.b (10 points)

**Compute what % of the predictor data is missing?**

```{r}
# ... code ...
```

* ...optional observation... *

**Compute percent of missing data by outcome label and identify classes with highest percent missing values. An example of this calculation: if there are two predictors and 10 rows of data with 5 missing data points then % missing = 5 \* 100 / (2\*10) = 25%**

```{r}
#... code ...
```

## Problem 2.2 (10 points)

The caret package contains a QSAR data set from Mente and Lombardo (2005). Here, the ability of a chemical to permeate the blood-brain barrier was experimentally determined for 208 compounds. 134 descriptors were measured for each compound.

### 2.2.a Load the data:

```{r 2-2-a}
library(caret)
data(BloodBrain)
# use ?BloodBrain to see more details
```

The numeric outcome is contained in the vector `logBBB` while the predictors are in the data frame `bbbDescr`.

### 2.2.b (5 points)

**Do any of the individual predictors have degenerate distributions?**

```{r}
# ... code ...
```

*... answer ... *

### 2.2.c (5 points)

**Generally speaking, are there strong relationships between the predictor data?**

```{r}
# ... code ...
```

**If so, how could correlations in the predictor set be reduced?**

```{r}
# ... code ...
```

**Does this have a dramatic effect on the number of predictors available for modeling?**

*... observation...*

## Problem 2.3 (10 points)

Consider the permeability data set described in Sect. 1.4. of the textbook. The objective for this data is to use the predictors to model compounds “permeability”.

```{r}
library(AppliedPredictiveModeling)
data(permeability) # this creates two matrices fingerprints and permeability 
permeabilitydf <- as_tibble(fingerprints) |> 
    mutate(permeability = permeability) 
```

### 2.3.a (5 points)

**What data splitting method(s) would you use for these data? Explain.**

```{r}
# ... code ...
```

*... answer ...*

### 2.3.b (5 points)

**Using tools described in this chapter, provide code for implementing your approach(es).**

```{r}
set.seed(503) # set seed for reproducibility
#... code ...
```

## Problem 2.4 (20 points)

Partial least squares was used to model the yield of a chemical manufacturing process (Sect. 1.4). The data can be found in the AppliedPre- dictiveModeling package and can be loaded using:

```{r}
library(AppliedPredictiveModeling)
data(ChemicalManufacturingProcess) 
```

The objective of this analysis is to find the number of PLS components that yields the optimal R^2^ value. PLS models with 1 through 10 components were each evaluated using five repeats of 10-fold cross-validation and the results are presented in the following table:

```{r}
#| echo: false
library(gt)
pca_table <- tibble(
    Components = 1:10,
    Mean = c(0.444, 0.500, 0.533, 0.545, 0.542, 
                    0.537, 0.534, 0.534, 0.520, 0.507),
    `Std. Error` = c(0.0272, 0.0298, 0.0302, 0.0308, 0.0322, 
                   0.0327, 0.0333, 0.0330, 0.0326, 0.0324)
)

gt(pca_table) |> 
    tab_header(title = md("Resampled R<sup>2</sup>")) |> 
    tab_options(
        data_row.padding = px(2),    # Specifically target data rows for more compactness
  )
```

### 2.4.a (7 points)

**Using the “one-standard error” method, what number of PLS components provides the most parsimonious model?**

*... answer ...*

### 2.4.b (7 points)

**If a 10% loss in optimal R2 is acceptable, then what is the optimal number of PLS components?**

*... answer ...*

### 2.4.c (3 points)

**Several other models with varying degrees of complexity were trained and tuned and the results are presented in Figure below. If the goal is to select the model that optimizes R^2^, then which model(s) would you choose, and why?**

![](images/M2-A2-image-Q4_1.png)

*...answer...*

### 2.4.d (3 points)

**Prediction time, as well as model complexity are other factors to consider when selecting the optimal model(s). Given each model’s prediction time, model complexity, and R2 estimates, which model(s) would you choose, and why?**

*...answer...*

## Problem 2.5 (30 points)

Brodnjak-Vonina et al. (2005) develop a methodology for food laboratories to determine the type of oil from a sample. In their procedure, they used a gas chromatograph (an instrument that separates chemicals in a sample) to measure seven different fatty acids in an oil. These measurements would then be used to predict the type of oil in a food sample. To create their model, they used 96 samples of seven types of oils.

These data can be found in the `caret` package using `data(oil)`. The oil types are contained in a factor variable called `oilType`. The types are pumpkin (coded as A), sunflower (B), peanut (C), olive (D), soybean (E), rapeseed (F) and corn (G).

```{r}
library(caret)
data(oil) 
```

### 2.5.a (10 points)

**Use the sample function in base R to create a completely random sample of 60 oils. How closely do the frequencies of the random sample match the original samples? Repeat this procedure several times to understand the variation in the sampling process.**

```{r}
set.seed(503)
#...code...
```

*...report observations...*


### 2.5.b (5 points)

**Use the caret package function `createDataPartition` to create a stratified random sample. How does this compare to the completely random samples?**

```{r}
#... code ...
```

*...observation...*



### 2.5.c (5 points)

**With such a small sample size, what are the options for determining performance of the model? Should a test set be used?**

*...answer...*

### 2.5.d (10 points)

One method for understanding the uncertainty of a test set is to use a confidence interval. To obtain a confidence interval for the overall accuracy, the based R function binom.test can be used. It requires the user to input the number of samples and the number correctly classified to calculate the interval. For example, suppose a test set sample of 20 oil samples was set aside and 76 were used for model training. For this test set size and a model that is about 80 % accurate (16 out of 20 correct), the confidence interval would be computed using

```{r}
p <- 0.8
n <- 20
binom.test(p * n,  n)
```

In this case, the width of the 95% confidence interval is 37.9%.

**Hint:**

```{r}
t_result <- binom.test(p * n,  n)
t_result$conf.int[2] - t_result$conf.int[1]
```

**Try different sample sizes and accuracy rates to understand the trade-off between the uncertainty in the results, the model performance, and the test set size.**

```{r}
#... code ...
```



*... report observations...*
