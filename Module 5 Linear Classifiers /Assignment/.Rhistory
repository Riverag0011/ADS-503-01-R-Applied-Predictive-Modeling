data(oil)
table(oilType)
# Split data to train and test sets
oilType <- as.data.frame(oilType)
oil_df <- cbind(fattyAcids, outcome = oilType$oilType)
set.seed(rseed)
train_index3 <- createDataPartition(y = oil_df$outcome, p = 0.8, list = FALSE)
oil_train <- oil_df[train_index3, ]
oil_test <- oil_df[-train_index3, ]
suppressWarnings({
# Set control
set.seed(rseed)
ctrl3 <- trainControl(method = "cv",
summaryFunction = defaultSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Create Linear Discriminant Analysis
ldaFit_o <- train(outcome ~ .,
data = oil_train,
method = "lda",
preProc = c("center", "scale"),
metric = "Accuracy",
classDist = as.numeric(class_weights),
trControl = ctrl3)
lda_train_predictions <- predict(ldaFit_o, newdata = oil_train)
ldaFit_cm <- confusionMatrix(lda_train_predictions, reference = oil_train$outcome)
ldaFit_cm
})
suppressWarnings({
# Create Penalized Logistic Regression
glmnGrid_o <- expand.grid(alpha = seq(0, 1, by = 0.1),
lambda = seq(.01, .2, length = 10))
glmnFit_o <- train(outcome ~ .,
data = oil_train,
method = "glmnet",
tuneGrid = glmnGrid_o,
preProc = c("center", "scale"),
metric = "Accuracy",
classDist = as.numeric(class_weights),
trControl = ctrl3)
optimal_glmnao <- glmnFit_o$bestTune$alpha
optimal_glmnlo <- glmnFit_o$bestTune$lambda
glmnmodel_o <- train(outcome ~ .,
data = oil_train,
method = "glmnet",
preProc = c("center", "scale"),
metric = "Accuracy",
trControl = ctrl3,
classDist = as.numeric(class_weights),
tuneGrid = expand.grid(alpha = optimal_glmnao,
lambda = optimal_glmnlo))
glmn_train_predictions <- predict(glmnmodel_o, newdata = oil_train)
glmn_cm <- confusionMatrix(glmn_train_predictions, reference = oil_train$outcome)
glmn_cm
})
suppressWarnings({
# Create Nearest Shrunken Centroids
nscGrido <- expand.grid(threshold = seq(0, 25, length = 30))
nscFit_o <- train(outcome ~ .,
data = oil_train,
method = "pam",
preProc = c("center", "scale"),
tuneGrid = nscGrido,
metric = "Accuracy",
trControl = ctrl3)
nsc_train_predictions <- predict(nscFit_o, newdata = oil_train)
nsc_cm <- confusionMatrix(nsc_train_predictions, reference = oil_train$outcome)
nsc_cm
})
# summarize the accuracies for all models in a table
model_accuracies <- data.frame(
Model = c("LDA", "GLMNet", "NSC"),
Accuracy = c(round(ldaFit_cm$overall["Accuracy"],4),
round(glmn_cm$overall["Accuracy"],4),
round(nsc_cm$overall["Accuracy"],4)))
model_accuracies |> gt() |> tab_header(title = "Model Accuracies")
knitr::purl("path/to/your/file.qmd", output = "path/to/output.R")
library(knitr)
knitr::purl("path/to/your/file.qmd", output = "path/to/output.R")
setwd("~/Desktop/MSADS5/ADS-503-01 Applied Predictive Modeling/Module 5 Linear Classifiers /Assignment")
setwd("/Users/gabirivera/Desktop/MSADS5/ADS-503-01 Applied Predictive Modeling/Module 5 Linear Classifiers /Assignment")
library(knitr)
knitr::purl("~/Desktop/MSADS5/ADS-503-01 Applied Predictive Modeling/Module 5 Linear Classifiers /Assignment/Rivera_Gabi_Assignment5.1.qmd", output = "~/Desktop/MSADS5/ADS-503-01 Applied Predictive Modeling/Module 5 Linear Classifiers /Assignment/Rivera_Gabi_Assignment5.1.R")
set.seed(rseed)
ctrl3 <- trainControl(method = "cv",
summaryFunction = defaultSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Create Linear Discriminant Analysis
ldaFit_o <- train(outcome ~ .,
data = oil_train,
method = "lda",
preProc = c("center", "scale"),
metric = "Accuracy",
classDist = as.numeric(class_weights),
trControl = ctrl3)
lda_train_predictions <- predict(ldaFit_o, newdata = oil_train)
ldaFit_cm <- confusionMatrix(lda_train_predictions, reference = oil_train$outcome)
ldaFit_cm
library(caret)
library(tidyverse)
library(gt)
library(AppliedPredictiveModeling)
library(corrplot)
library(ROSE)
library(pROC)
library(magrittr)
rseed <- 503
library(AppliedPredictiveModeling)
data(hepatic)
# ?hepatic
# Lump all compounds that cause injury into a "Yes" category:
outcome <- tibble(
any_damage = factor(ifelse(injury == "None", "No", "Yes"),
levels = c("Yes", "No") ))
#print a table
outcome |> count(any_damage) |>
gt() |>
grand_summary_rows(columns = n,
fns = list(total = ~sum(.)) )
suppressWarnings({
bio_df <- cbind(bio, outcome = outcome$any_damage)
# Remove low frequency predictors
filtered_bio <- bio_df[, -nearZeroVar(bio_df)]
remaining_predictors <- ncol(filtered_bio) - 1
cat("Predictors left after low frequencies are removed:", remaining_predictors)
# Remove highly correlated predictors
filtered_bio$outcome <- ifelse(filtered_bio$outcome == "No", 0, 1)
correlation_matrix <- cor(filtered_bio[, -1])
highly_correlated <- findCorrelation(correlation_matrix, cutoff = 0.75)
highly_correlated_names <- colnames(filtered_bio[, -1])[highly_correlated]
biodf_reduced <- filtered_bio[, -highly_correlated]
biodf_reduced$outcome <- ifelse(biodf_reduced$outcome == 0, "No", "Yes")
# Split Bio data set to training and test sets
set.seed(rseed)
train_index <- createDataPartition(y = biodf_reduced$outcome, p = 0.8, list = FALSE)
biodf_train <- biodf_reduced[train_index, ]
biodf_test <- biodf_reduced[-train_index, ]
biodf_train_bal <- ROSE(outcome ~ ., data = biodf_train)$data
# Build classification models
set.seed(rseed)
ctrl <- trainControl(method = "cv",
summaryFunction = twoClassSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Create Logistic Regression
lrFit <- train(outcome ~ .,
data = biodf_train_bal,
method = "glm",
metric = "ROC",
trControl = ctrl)
# Create Linear Discriminant Analysis
ldaFit <- train(outcome ~ .,
data = biodf_train_bal,
method = "lda",
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl)
# Create Penalized Logistic Regression
glmnGrid <- expand.grid(alpha = seq(0, 1, by = 0.1),
lambda = seq(.01, .2, length = 10))
glmnFit <- train(outcome ~ .,
data = biodf_train_bal,
method = "glmnet",
tuneGrid = glmnGrid,
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl)
optimal_glmna <- glmnFit$bestTune$alpha
optimal_glmnl <- glmnFit$bestTune$lambda
glmnmodel <- train(outcome ~ .,
data = biodf_train_bal,
method = "glmnet",
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl,
tuneGrid = expand.grid(alpha = optimal_glmna,
lambda = optimal_glmnl))
# Create Nearest Shrunken Centroids
nscGrid <- expand.grid(threshold = seq(0, 25, length = 30))
nscFit <- train(outcome ~ .,
data = biodf_train_bal,
method = "pam",
preProc = c("center", "scale"),
tuneGrid = nscGrid,
metric = "ROC",
trControl = ctrl)
})
suppressWarnings({
chem_df <- cbind(chem, outcome = outcome$any_damage)
# Remove low frequency predictors
filtered_chem <- chem_df[, -nearZeroVar(chem_df)]
remaining_predictors1 <- ncol(filtered_chem) - 1
cat("Predictors left after low frequencies are removed:", remaining_predictors1)
# Remove highly correlated predictors
filtered_chem$outcome <- ifelse(filtered_chem$outcome == "No", 0, 1)
correlation_matrix1 <- cor(filtered_chem[, -1])
highly_correlated1 <- findCorrelation(correlation_matrix1, cutoff = 0.75)
highly_correlated_names1 <- colnames(filtered_chem[, -1])[highly_correlated1]
chemdf_reduced <- filtered_chem[, -highly_correlated1]
chemdf_reduced$outcome <- ifelse(chemdf_reduced$outcome == 0, "No", "Yes")
# Split chem data set to training and test sets
set.seed(rseed)
train_index1 <- createDataPartition(y = chemdf_reduced$outcome, p = 0.8, list = FALSE)
chemdf_train <- chemdf_reduced[train_index1, ]
chemdf_test <- chemdf_reduced[-train_index1, ]
chemdf_train_bal <- ROSE(outcome ~ ., data = chemdf_train)$data
# Build classification models
set.seed(rseed)
ctrl1 <- trainControl(method = "cv", summaryFunction = twoClassSummary,
classProbs = TRUE, savePredictions = TRUE)
# Create Logistic Regression
clrFit <- train(outcome ~ .,
data = chemdf_train_bal,
method = "glm",
metric = "ROC",
trControl = ctrl1)
# Create Linear Discriminant Analysis
cldaFit <- train(outcome ~ .,
data = chemdf_train_bal,
method = "lda",
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl1)
# Create Penalized Logistic Regression
cglmnGrid <- expand.grid(alpha = seq(0, 1, by = 0.1),
lambda = seq(.01, .2, length = 10))
cglmnFit <- train(outcome ~ .,
data = chemdf_train_bal,
method = "glmnet",
tuneGrid = cglmnGrid,
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl1)
coptimal_glmna <- cglmnFit$bestTune$alpha
coptimal_glmnl <- cglmnFit$bestTune$lambda
cglmnmodel <- train(outcome ~ .,
data = chemdf_train_bal,
method = "glmnet",
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl1,
tuneGrid = expand.grid(alpha = coptimal_glmna,
lambda = coptimal_glmnl))
# Create Nearest Shrunken Centroids
cnscGrid <- expand.grid(threshold = seq(0, 25, length = 30))
cnscFit <- train(outcome ~ .,
data = chemdf_train_bal,
method = "pam",
preProc = c("center", "scale"),
tuneGrid = cnscGrid,
metric = "ROC",
trControl = ctrl1)
})
suppressWarnings({
# Bio Models Predictions and Confusion Matrix
testResults <- data.frame(obs = biodf_test$outcome,
LR = predict(lrFit, biodf_test[,1:81]))
testResults$LDA <- predict(ldaFit, biodf_test[,1:81])
testResults$GLMNet <- predict(glmnmodel, biodf_test[,1:81])
testResults$NSC <- predict(nscFit, biodf_test[,1:81])
testResults$obs <- factor(testResults$obs, levels = levels(testResults$LR))
confusionMatrix(testResults$LR, testResults$obs, positive = "Yes")
confusionMatrix(testResults$LDA, testResults$obs, positive = "Yes")
confusionMatrix(testResults$GLMNet, testResults$obs, positive = "Yes")
confusionMatrix(testResults$NSC, testResults$obs, positive = "Yes")
# Chem Models Predictions and Confusion Matrix
testResults1 <- data.frame(obs = chemdf_test$outcome,
LR = predict(clrFit, chemdf_test[,1:73]))
testResults1$LDA <- predict(cldaFit, chemdf_test[,1:73])
testResults1$GLMNet <- predict(cglmnmodel, chemdf_test[,1:73])
testResults1$NSC <- predict(cnscFit, chemdf_test[,1:73])
testResults1$obs <- factor(testResults1$obs, levels = levels(testResults1$LR))
confusionMatrix(testResults1$LR, testResults1$obs, positive = "Yes")
confusionMatrix(testResults1$LDA, testResults1$obs, positive = "Yes")
confusionMatrix(testResults1$GLMNet, testResults1$obs, positive = "Yes")
confusionMatrix(testResults1$NSC, testResults1$obs, positive = "Yes")
# Bio ROC Plots
roc_lrFit <- roc(response = lrFit$pred$obs,
predictor = lrFit$pred$Yes,
levels = rev(levels(lrFit$pred$obs)))
roc_ldaFit <- roc(response = ldaFit$pred$obs,
predictor = ldaFit$pred$Yes,
levels = rev(levels(ldaFit$pred$obs)))
roc_glmnmodel <- roc(response = glmnmodel$pred$obs,
predictor = glmnmodel$pred$Yes,
levels = rev(levels(glmnmodel$pred$obs)))
roc_nscmodel <- roc(response = nscFit$pred$obs,
predictor = nscFit$pred$Yes,
levels = rev(levels(nscFit$pred$obs)))
plot(roc_lrFit, col = "darkblue", main = "Bio Data ROC Curves")
plot(roc_ldaFit, col = "pink", add = TRUE)
plot(roc_glmnmodel, col = "darkgreen", add = TRUE)
plot(roc_nscmodel, col = "violet", add = TRUE)
legend("bottomright", legend = c("lrFit", "ldaFit", "glmnmodel", "nscmodel"),
col = c("darkblue", "pink", "darkgreen", "violet"), lty = 1)
# Chem ROC Plots
roc_clrFit <- roc(response = clrFit$pred$obs,
predictor = clrFit$pred$Yes,
levels = rev(levels(clrFit$pred$obs)))
roc_cldaFit <- roc(response = cldaFit$pred$obs,
predictor = cldaFit$pred$Yes,
levels = rev(levels(cldaFit$pred$obs)))
roc_cglmnmodel <- roc(response = cglmnmodel$pred$obs,
predictor = cglmnmodel$pred$Yes,
levels = rev(levels(cglmnmodel$pred$obs)))
roc_cnscmodel <- roc(response = cnscFit$pred$obs,
predictor = cnscFit$pred$Yes,
levels = rev(levels(cnscFit$pred$obs)))
plot(roc_clrFit, col = "darkblue", main = "Chem Data ROC Curves")
plot(roc_cldaFit, col = "pink", add = TRUE)
plot(roc_cglmnmodel, col = "darkgreen", add = TRUE)
plot(roc_cnscmodel, col = "violet", add = TRUE)
legend("bottomright", legend = c("lrFit", "ldaFit", "glmnmodel", "nscmodel"),
col = c("darkblue", "pink", "darkgreen", "violet"), lty = 1)
})
# Calculate AUC of each model
calc_auc <- function(obs, LR, LDA, GLMNet, NSC) {
roc_lr <- roc(obs, as.numeric(LR))
roc_lda <- roc(obs, as.numeric(LDA))
roc_glmnet <- roc(obs, as.numeric(GLMNet))
roc_nsc <- roc(obs, as.numeric(NSC))
auc_lr <- auc(roc_lr)
auc_lda <- auc(roc_lda)
auc_glmnet <- auc(roc_glmnet)
auc_nsc <- auc(roc_nsc)
return(c(auc_lr, auc_lda, auc_glmnet, auc_nsc))}
bio_models <- c("LR", "LDA", "GLMNet", "NSC")
bio_aucs <- calc_auc(testResults$obs, testResults$LR, testResults$LDA,
testResults$GLMNet, testResults$NSC)
chem_models <- c("LR", "LDA", "GLMNet", "NSC")
chem_aucs <- calc_auc(testResults1$obs, testResults1$LR, testResults1$LDA,
testResults1$GLMNet, testResults1$NSC)
# Table AUC-ROC Comparison
summary_table <- data.frame(
Model = c(rep(bio_models, each = 1), rep(chem_models, each = 1)),
Dataset = c(rep("Biological", times = length(bio_models)),
rep("Chemical", times = length(chem_models))),
AUC = c(bio_aucs, chem_aucs))
summary_table |> gt() |>
tab_header(title = "Summary of AUC Values for Diff. Models and Datasets using Test Data") |>
fmt_number(columns = vars(AUC), decimals = 3)
# Top 5 predictors of bio df using LR
bioImp <- varImp(lrFit, scale = FALSE)
plot(bioImp, top = 5, main = "Top 5 predictors of Bio df using LR")
# Top 5 predictors of chem df using NSC
chemImp1 <- varImp(cnscFit, scale = FALSE)
plot(chemImp1, top = 5, main = "Top 5 predictors of Bhem df using NSC")
#Cant run LDA model through varImp or any alternatives
# Combine bio and chem datasets
hepatic_df <- cbind(bio, chem, outcome = outcome$any_damage)
# Remove low frequency predictors
filt_hepatic <- hepatic_df[, -nearZeroVar(hepatic_df)]
remaining_predictors2 <- ncol(filt_hepatic) - 1
cat("Predictors left after low frequencies are removed:", remaining_predictors2)
# Remove highly correlated predictors
filt_hepatic$outcome <- ifelse(filt_hepatic$outcome == "No", 0, 1)
correlation_matrix2 <- cor(filt_hepatic[, -1])
highly_correlated2 <- findCorrelation(correlation_matrix2, cutoff = 0.70)
highly_correlated_names2 <- colnames(filt_hepatic[, -1])[highly_correlated2]
hepatic_reduced <- filt_hepatic[, -highly_correlated2]
hepatic_reduced$outcome <- ifelse(hepatic_reduced$outcome == 0, "No", "Yes")
# Split Bio data set to training and test sets
set.seed(rseed)
train_index2 <- createDataPartition(y = hepatic_reduced$outcome, p = 0.8, list = FALSE)
hepatic_train <- hepatic_reduced[train_index2, ]
hepatic_test <- hepatic_reduced[-train_index2, ]
hepatic_train_bal <- ROSE(outcome ~ ., data = hepatic_train)$data
# Build classification models
set.seed(rseed)
ctrl2 <- trainControl(method = "cv",
summaryFunction = twoClassSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Create Logistic Regression
lrFit_h <- train(outcome ~ .,
data = hepatic_train_bal,
method = "glm",
metric = "ROC",
trControl = ctrl2)
# Create Linear Discriminant Analysis
ldaFit_h <- train(outcome ~ .,
data = hepatic_train_bal,
method = "lda",
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl2)
# Create Penalized Logistic Regression
glmnGrid_h <- expand.grid(alpha = seq(0, 1, by = 0.1),
lambda = seq(.01, .2, length = 10))
glmnFit_h <- train(outcome ~ .,
data = hepatic_train_bal,
method = "glmnet",
tuneGrid = glmnGrid_h,
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl2)
optimal_glmnah <- glmnFit_h$bestTune$alpha
optimal_glmnlh <- glmnFit_h$bestTune$lambda
glmnmodel_h <- train(outcome ~ .,
data = hepatic_train_bal,
method = "glmnet",
preProc = c("center", "scale"),
metric = "ROC",
trControl = ctrl2,
tuneGrid = expand.grid(alpha = optimal_glmnah,
lambda = optimal_glmnlh))
# Create Nearest Shrunken Centroids
nscGridh <- expand.grid(threshold = seq(0, 25, length = 30))
nscFit_h <- train(outcome ~ .,
data = hepatic_train_bal,
method = "pam",
preProc = c("center", "scale"),
tuneGrid = nscGridh,
metric = "ROC",
trControl = ctrl2)
suppressWarnings({
# Run test through models
testResults2 <- data.frame(obs = hepatic_test$outcome,
LR = predict(lrFit_h, hepatic_test[,1:143]))
testResults2$LDA <- predict(ldaFit_h, hepatic_test[,1:143])
testResults2$GLMNet <- predict(glmnmodel_h, hepatic_test[,1:143])
testResults2$NSC <- predict(nscFit_h, hepatic_test[,1:143])
# Calculate AUC of each model
calc_auc <- function(obs, LR, LDA, GLMNet, NSC) {
roc_lr <- roc(obs, as.numeric(LR))
roc_lda <- roc(obs, as.numeric(LDA))
roc_glmnet <- roc(obs, as.numeric(GLMNet))
roc_nsc <- roc(obs, as.numeric(NSC))
auc_lr <- auc(roc_lr)
auc_lda <- auc(roc_lda)
auc_glmnet <- auc(roc_glmnet)
auc_nsc <- auc(roc_nsc)
return(c(auc_lr, auc_lda, auc_glmnet, auc_nsc))}
hepatic_models <- c("LR", "LDA", "GLMNet", "NSC")
hepatic_aucs <- calc_auc(testResults2$obs, testResults2$LR, testResults2$LDA,
testResults2$GLMNet,testResults2$NSC)
# Table AUC-ROC Comparison
summary_table2 <- data.frame(
Model = c(rep(hepatic_models, each = 1)),
Dataset = c(rep("Hepatic", times = length(hepatic_models))),
AUC = c(hepatic_aucs))
summary_table2 |> gt() |>
tab_header(title = "Summary of AUC Values Using Test Data") |>
fmt_number(columns = vars(AUC), decimals = 3)
})
# Top 5 predictors of hepatic df using LR
hepImp <- varImp(lrFit_h)
plot(hepImp, top = 5, main = "Top 5 predictors of Hepatic df using LR")
data(oil)
table(oilType)
# Split data to train and test sets
oilType <- as.data.frame(oilType)
oil_df <- cbind(fattyAcids, outcome = oilType$oilType)
set.seed(rseed)
train_index3 <- createDataPartition(y = oil_df$outcome, p = 0.8, list = FALSE)
oil_train <- oil_df[train_index3, ]
oil_test <- oil_df[-train_index3, ]
set.seed(rseed)
ctrl3 <- trainControl(method = "cv",
summaryFunction = defaultSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Create Linear Discriminant Analysis
ldaFit_o <- train(outcome ~ .,
data = oil_train,
method = "lda",
preProc = c("center", "scale"),
metric = "Accuracy",
classDist = as.numeric(class_weights),
trControl = ctrl3)
set.seed(rseed)
ctrl3 <- trainControl(method = "cv",
summaryFunction = defaultSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Create Linear Discriminant Analysis
ldaFit_o <- train(outcome ~ .,
data = oil_train,
method = "lda",
preProc = c("center", "scale"),
metric = "Accuracy",
classDist = as.numeric(class_weights),
trControl = ctrl3)
set.seed(rseed)
ctrl3 <- trainControl(method = "cv",
summaryFunction = defaultSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Create Linear Discriminant Analysis
ldaFit_o <- train(outcome ~ .,
data = oil_train,
method = "lda",
preProc = c("center", "scale"),
metric = "Accuracy",
classDist = as.numeric(class_weights),
trControl = ctrl3)
set.seed(rseed)
ctrl3 <- trainControl(method = "cv",
summaryFunction = defaultSummary,
classProbs = TRUE,
savePredictions = TRUE)
# Create Linear Discriminant Analysis
ldaFit_o <- train(outcome ~ .,
data = oil_train,
method = "lda",
preProc = c("center", "scale"),
metric = "Accuracy",
trControl = ctrl3)
lda_train_predictions <- predict(ldaFit_o, newdata = oil_train)
ldaFit_cm <- confusionMatrix(lda_train_predictions, reference = oil_train$outcome)
ldaFit_cm
